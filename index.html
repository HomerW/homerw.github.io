<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Homer Walke</title>

  <meta name="author" content="Homer Walke">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Homer Walke</name>
              </p>
              <p style="text-align:center">homer underscore walke at berkeley dot edu</p>
              <p>
                 Hello! I'm a PhD student in computer science at UC Berkeley where I'm advised by
                 <a href="https://people.eecs.berkeley.edu/~svlevine/">Professor Sergey Levine.</a>
                 I'm interested in building intelligent agents that leverage
                 prior experience to generalize to new tasks and environments
                 with minimal human supervision. Previously, I graduated from
                 Brown University where I worked in the Robotics Group with
                 <a href="https://www.littmania.com/">Professor Michael Littman</a>
                 and in the Visual Computing Group with
                 <a href="http://dritchie.github.io">Professor Daniel Ritchie</a>.
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile-circle.png"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two">
                  <img src="images/flap.png" width=160></img>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.04703">
                <papertitle>Generalization with Lossy Affordances: Leveraging Broad Offline Data for Learning Visuomotor Tasks</papertitle>
              </a>
              <br>
              <a href="https://kuanfang.github.io/">Kuan Fang</a>,
              <a href="https://patrickyin.me/">Patrick Yin</a>, 
              <a href="https://ashvin.me/">Ashvin Nair</a>,
              <strong>Homer Walke</strong>,
              Gengchen Yan,
              <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>,
              <br>
              <em>CoRL</em>, 2022
              <br>
              <a href="https://openreview.net/forum?id=esOrVR_8-rc">OpenReview</a>, <a href="https://sites.google.com/view/project-flap">website</a>
              <p></p>
              <p>We propose a method for learning lossy state representations in offline goal-conditioned RL that facilitate generalization 
                 across visually different scenes. By planning in this lossy representation space, our method allows for combining multiple 
                 goal-reaching skills from prior data to solve new tasks.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two">
                <img src="images/ariel.gif" width=160, height=160></img>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.04703">
                <papertitle>Don't Start From Scratch: Leveraging Prior Data to Automate Robotic Reinforcement Learning</papertitle>
              </a>
              <br>
              <strong>Homer Walke</strong>,
              Jonathan Yang,
              Albert Yu,
              <a href="https://aviralkumar2907.github.io/">Aviral Kumar</a>,
              Jedrzej Orbik,
              <a href="https://www.avisingh.org/">Avi Singh</a>,
              <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>,
              <br>
              <em>CoRL</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2207.04703">arXiv</a>, <a href="https://sites.google.com/view/ariel-berkeley">website</a>
              <p></p>
              <p>We demonstrate that incorporating prior data into robotic reinforcement learning enables 
                 autonomous learning, substantially improves sample-efficiency of learning, and enables better 
                 generalization. Our method learns new robotic manipulation skills directly from image observations 
                 and with minimal human intervention to reset the environment. 
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two">
                <img src="images/lest.png" width=160></img>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.13045">
                <papertitle>PLAD: Learning to Infer Shape Programs with Pseudo-Labels and Approximate Distributions</papertitle>
              </a>
              <br>
              <a href="https://rkjones4.github.io/">R. Kenny Jones</a>,
              <strong>Homer Walke</strong>,
              <a href="http://dritchie.github.io">Daniel Ritchie</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2011.13045">arXiv</a>
              <p></p>
              <p>We propose a method for shape program inference based on self-training that
                 works with black box program executors. We demonstrate that it converges
                 faster and achieves better reconstruction quality than policy gradient reinforcement learning.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two">
                <img src="images/deepltl.png" width=160></img>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2111.04147">
                <papertitle>Learning Finite Linear Temporal Logic Specifications with a Specialized Neural Operator</papertitle>
              </a>
              <br>

              <strong>Homer Walke</strong>,
              <a href="#">Daniel Ritter</a>,
              <a href="http://cs.brown.edu/~ctrimbac/">Carl Trimbach</a>,
              <a href="https://www.littmania.com/">Michael Littman</a>
              <br>
              <em>arXiv</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2111.04147">arXiv</a>, <a href="homer_walke_honors_thesis.pdf">Undergraduate Honors Thesis</a>
              <p></p>
              <p>
                 We developed an approach for synthesizing LTL formulas from demonstrations using
                 deep networks outfitted with a custom neural operator. We show that our method
                 learns LTL formulas that capture extended sequences of actions, scaling better
                 than SAT-based approaches.
              </p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
				<tr>
					<td>
						<p align="right">
							<font size="2">
								<a href="https://jonbarron.info/">template</a>
								</font>
						</p>
					</td>
				</tr>
			</table>

      </td>
    </tr>
  </table>
</body>

</html>
